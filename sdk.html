<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Software</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">
  <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

  <!-- Custom styles for this template -->
  <link href="css/clean-blog.min.css" rel="stylesheet">
  <link rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>

<body>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand" href="index.html">OSU ECE 44X</a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
       Menu
        <i class="fas fa-bars"></i>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="index.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="quickStartGuide.html">QUICK START GUIDE</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="hardware.html">HARDWARE</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="software.html">SOFTWARE</a>
          <li class="nav-item">
            <a class="nav-link" href="resources.html">RESOURCES</a>
          </li>
		<li class="nav-item">
            <a class="nav-link" href="glossary.html">GLOSSARY</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Page Header -->
  <header class="masthead" style="background-image: url('img/post-bg.jpg')">
    <div class="overlay"></div>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <div class="post-heading">
            <h1>Software Interfaces</h1>
            <h2 class="subheading">Common applications</h2>
          </div>
        </div>
      </div>
    </div>
  </header>

  <!-- Post Content -->
  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
	  <h1 class="section-heading">General Purpose Computing</h2>
		<p>Though GPUs were originally developed for graphical-processing, their parallelism and speed facilitatd the 
	           development of general-purpose GPU computing (GPGPU), non-graphics applications of GPUs implemented to speed
		   up programs. Since its unveiling in 2001, GPGPU programming has spawned a host of programming paradigms that
			give users access to their GPU through API allowing them to customize function. GPGPU programming finds various
			applications from DNA analysis, search algorithms, and molecular simulations.</p>
		<p> What the listed applications have in common is parallelism and throughput. These take advantage of GPU to 
			process many simple elements in parallel at great speeds. This is incredibly ideal for molecular simulations,
			but also useful for image processing, especially on the pixel level.</p>
		
          <h2 class="section-heading">GPGPU Access</h2>
		<p> There exist several common libraries to facilitate GPGPU programming. These include the Nvidia's CUDA and Khronos
			Group's OpenCL. Both libraries require downloads from the web and in Nvidia's case a special compiler, nvcc. 
			OpenCL is open-source and has support on Intel, AMD< Nvidia, and ARM platforms. While CUDA is proprietary, it 
			is well-supported by NVidia and widely used. Furthermore, taking into account </p>
		<p> CUDA (Compute Unified Device Architecture) is an Nvidia-produced GPGPU API designed for nonspecialists. CUDA 
			interacts directly with GPU threads and allows users to specify what threads they want to be executed in 
			parallel as well as if they would like for it to be executed on multiple GPUs. Nvidia also provides CUDA 
			support in the form of the CUDA Toolkit, providing parallel algorithm support, CUDA signal processing, and 
			CUDA linear algebra libraries. This allows CUDA code to be easily fitted upon the existing C code.</p> 
		<p>
		</p>

          <p> Of course, not all programmers are necessarily interested in diving into CUDA programming, and there are other 
	      interfaces to take command of the GPU. Some commonly applied libraries are OpenCL, OpenACC, Numba, and CUDA. 
	      These libraries allow programmers to have easy access to the GPU, and also allows them to execute traditional GPU 
	      applications, granting them powerful control over the specific application of the GPU. Numba is a python library 
	      with inbuilt functions that allow quick and easy access to the GPU, with specific lines to specify the parts of code 
	      to be executed in parallel. Numba is based around the syntax of NumPy and Scipy, common libraries for handling the 
	      representation of code as matrices for mathematical computation. Numba compiles simultaneously for the CPU and the GPU 
	      and dramatically increases array processing. </p> 
		
          <p> OpenACC provides similar support, though in the C language. OpenACC accomplishes parallel programming via a series of 
	      simple, easy-to-understand preprocessor directives. Once the environment has been properly set up, the parallelism is 
	      fairly straight-forward to achieve. However, OpenACC isn’t simply restricted to these low-level applications, and is 
	      powerful enough to give users control over the ways they desire to parallelize loops and allocate data.</p> 
		
	  <h1 class="section-heading">Nvidia SDKs</h2>
		<p>Nvidia provides many Software Development Kits (SDKs) that simplify any new engineer's interactions with GPUs. It is leaps and bounds above its competitors AMD and Intel in providing resources to hobbyists or individual engineers. (Nevertheless, all three companies actively engage in collaborations with universities and other corporations). SDKs are like coding libraries but designed to specifically suit the capabilities of an Nvidia system.</p>

		<p>The JetPack SDK is probably the best place to start when approaching a new Nvidia system. It allows new 
			users to set up their embedded devices with an operating system and proprietary software NVIDIA Jetpack is 
			an SDK package equipped with several tools to assist in the building of AI applications, providing support 
			to the AGX Xavier, TX2, TX1, and Jetson Nano. It is also referred to as the Nvidia SDK Manager.</p>

		<p>The Nvidia SDK Manager requires two hardware components. First, the user must have a host computer running Ubuntu 
			16.04 or 18.04, a working Internet connection, and a Jetson device. The host device must have a minimum of 40GB
			of free disk space whereas the Jetson must have at least 25GB of free disk space. Once a USB 2.0 connection has
			been established between the two devices, the Jetson can be easily set up with the host computer. </p>

          <p>The SDK has a GUI which guides the user on setting up the Jetson as well as any additional packages that need to be 
		  installed. This is the only way to put an operating system onto the Jetson. The SDK manager can be used later to
		  update the SDK installation on the system.</p>

          <p>Next, we will explore some other SDKs that Nvidia provides. These SDKs should give you a general idea of the various 
		  high-level applications that can be tackled using a GPU.</p>

          <h2 class="section-heading">Deepstream SDK</h2>

          <p>The DeepStreak SDK is a computer-vision library that includes AI-based video processing with sensor processing. Deepstream 
		  relies on the Gstreamer paradigm for multimedia processing. DeepStream is free of charge and downloadable from the 
		  Nvidia website. Be sure to consult the Nvidia website for the various compatibility requirements of each version of 
		  DeepStream.</p>

          <p>DeepStream can be installed via Jetpack and comes with several demos to get an individual started on coding for machine 
		  learning and computer vision applications. On a device that is set up, DeepStream can be installed via Ubuntu command
		  “sudo apt-get”, if it was not installed via the SDK.</p>

          <p>Nvidia DeepStream SDK is an important component of NVIDIA Metropolis, which has one of its applications collection vehicle 
		  taxes in Jakarta. In the past, it has also been found on Tesla cars. Many of the sample applications associated with 
		  this SDK are designed to run on self-driving cars.</p>
          
          <h2 class="section-heading">Isaac SDK</h2>

          <p>The Isaac SDK is developed to support the control of mobile robots. It has a structure similar to that of ROS with support 
		  for visualization, simulation, and more. The Isaac SDK is fundamentally based on the Isaac Robot Engine with support 
		  for a variety of math-planning and visualization algorithms. Simulation is a key stage in robotics design and a critical
		  component to prevent product failures. The SDK package also includes tutorials for several basic packages controlling 
		  existing robots, such as the Kaya.  </p>

          <h2 class="section-heading">TensorRT</h2>
          
          <p>TensorRT comes with the ONNX (Open Neural network Exchange) parser with support for video-processing and natural language processing [15]. It provides good support for general AI and machine-learning applications. The following diagram indicates how TensorRT functions within a larger system. On the diagram, below it is indicated that Tensorflow takes in one of the common machine-learning libraries and outputs directly to the physical hardware of the embedded system.</p>
         
          
          <h2 class="section-heading">Machine Learning Libraries</h2>
          
          <p> It must be emphasized, even with the application of GPGPU programming to other fields, the major application of GPU programming remains rooted in the area of machine learning and image processing. This means that an engineer working with a GPU should be familiar, if not fluent, with the common machine libraries used in industry. Tensorflow and PyTorch are among the most popular and widely-used.</p>

          <p> Facebook’s PyTorch is an open-source, machine-learning library derived from the Torch, a repository of machine-learning libraries written in Lua. In simple terms, its two top-level functions are access to machine-learning algorithms and a NumPy based interface that supports the GPU-accelerated image processing. Broadly speaking, its API is divided into the following components: torchtext for natural language processing, torchaudio for spoken language processing, torchvision for image processing, and torch for general access to machine-learning algorithms. </p>

          <p> Google Brain’s Tensorflow is written C++ with Python bindings. In Summer 2019, Google released Tensorflow2, a major overhaul of the previous version of Tensorflow. Though it has support for Java and Go, the most stable version of Tensorflow2 is the python version. Just as PyTorch implements the Torch interface, Tensorflow relies on the Keras machine-learning interface. Its API is more detailed but also harder to use as a beginner, with separate libraries for audio processing, data handling, debugging, and error checking, as well as a Keras API (tf.keras) for training models. </p>

          <p> Both libraries can accomplish the same end-goal, but there are minor differences between the two that can dramatically influence project deadlines, depending on the needs of the individual engineer. PyTorch’s syntax is rooted in NumPy and is widely regarded as having better API documentation and support, but lacking a native data visualizer that Tensorflow provides, meaning that users will have to export data to an alternate visualizer to track the process of their programs. In addition, Tensorflow 2 is relatively new. Unlike other software updates, Tensorflow 2 dramatically overhauled the previous version of Tensorflow [22, 23]. While Tensorflow 2 promises advantages over the previous version, it is young and untested, meaning that programmers that run into issues have relatively fewer sources to consult compared to users of PyTorch. </p> 
		
	<h2 class="section-heading">Introduction to Git</h2>

	<p>Git is a software development tool that allows for the tracking of changes to files. It is the base code that GitHub itself runs on. As such, understanding it is important to understanding GitHub as a whole. This section of the ReadMe will serve as a basic tutorial for the Git command line. </p>

	<h3>Step 1: Installing Git</h3>

	<p>To start, you will need to download Git. If you have a Windows computer, click <a href=https://git-scm.com/download/win">here</a>. On macOS, open up OSX Terminal and type <code>git --version</code>, and you will be prompted to install it if it was not already. </p>
  
	<h3>Step 2: Using the terminal to create a repository.</h3>

	<p>Open up your terminal (Windows Command Prompt on Windows or OS X Terminal on Macintosh). First, type in the word "git", and hit enter, just to make sure it installed correctly. From there, it's time to create the folder to host your repository. Type <code>mkdir folderName</code>, where folderName is the name of your repository. This will create a folder (or, director) with that name. To enter that folder, type <code>cd folderName</code>. </p>

	<h3>Step 3: Creating the ReadMe</h3>

	<p>The ReadMe file in a repository contains information about the other files in the repository. It should say what's included in the repository, like is seen in the first section of this file. In order to create a ReadMe for your preexisting directory, like the one you're in now,, type <code>echo "# folderName" >> README.md</code>.</p>
	<p>With the ReadMe created, it's time to access Git. Type <code>git init</code> to intiialize Git within this directory. Now, it's always good to know when changes have occued to a file. To do so, type <code>git add README.md</code>. You can do this for any file that you want the history of changes to be saved for.</p> 

	<h3>Step 4: Creating a Commit</h3>
	<p>A "Commit", in the Git world, is more or less how you save a change to a repository. It is a statement that you are commiting to the changes that you have made. In order to do this for the first time in a directory, type <code>git commit -m "first commit"</code>. </p>

	<h3>Step 5: Creating a GitHub repository</h3>

	<p>Now, you'll need to be sure you have a Github account. Once you do, go to <a href="github.com">the GitHub website</a> and choose "Start a project".</p>
	<p>From here, you will find yourself entering the basic information for your repository. The name, the owner, whether or not the project is publicly accessible, etc. Once all that is filmed out, click "Create repository".</p>

	<h2>Step 6: Exporting a respository to GitHub</h2>

	<p>It's finally time to upload this directory to GitHub. From the command terminal, type <code>git remote add origin https://github.com/yourUsername/folderName.git</code>. This code adds a remote named Origin to the address listed in the code. Origin is just a placehoder name, so if you want to use another name you can.</p>
        </div>
      </div>
    </div>
  </article>

  <hr>

  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <ul class="list-inline text-center">
            <li class="list-inline-item">
              <a href="https://github.com/osusdgpu/osusdgpu.github.io">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          </ul>
          <p class="copyright text-muted">Copyright &copy; Your Website 2019</p>
        </div>
      </div>
    </div>
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/clean-blog.min.js"></script>

</body>

</html>
